# MVP-004: Define Data Model & Database Schema

## Ticket Overview

**Ticket ID:** MVP-004  
**Title:** Define Data Model & Database Schema  
**Type:** Task  
**Description:** Based on the Data Model document, create database schema definitions, entity relationship diagrams, and migration scripts for the core entities (Users, Patients, Appointments, Encounters).  
**Owner:** Anil  
**Reviewers:** Kushal, Rohith  
**Story Points:** 8  
**Priority:** High  
**Dependencies:** MVP-001  

## The Story Behind the Ticket

### Why This Ticket Matters

After establishing our project vision, architecture, and development environment in the previous tickets, MVP-004 focused on defining the data foundation of our application. The data model is the backbone of any application, especially in a healthcare context where data integrity, relationships, and access patterns are critical.

This ticket was essential because:

1. It translated our conceptual data model into concrete database schemas
2. It defined the relationships between core entities like Users, Patients, Appointments, and Encounters
3. It established the data access patterns that would guide our application's performance
4. It created migration scripts to ensure consistent database setup across environments

A well-designed data model is crucial for application performance, scalability, and maintainability. MVP-004 was about getting this foundation right from the start, avoiding costly data restructuring later in the project.

### The Technical Implementation

#### 1. Database Schema Definitions

We created comprehensive schema definitions for PostgreSQL, focusing on the core entities of our application. Here's an example of the Users table schema:

```sql
-- Users Table Schema
-- Represents doctors, nurses, and administrative staff

CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    full_name VARCHAR(100) NOT NULL,
    role VARCHAR(20) NOT NULL,  -- 'doctor', 'nurse', 'admin', etc.
    specialty VARCHAR(50),      -- For doctors
    phone VARCHAR(20),
    profile_image_url VARCHAR(255),
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    last_login_at TIMESTAMP,
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    preferences JSONB,          -- User preferences and settings
    CONSTRAINT valid_role CHECK (role IN ('doctor', 'nurse', 'admin', 'receptionist'))
);

-- Indexes
CREATE INDEX IF NOT EXISTS idx_users_role ON users(role);
CREATE INDEX IF NOT EXISTS idx_users_specialty ON users(specialty) WHERE specialty IS NOT NULL;
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_users_status ON users(status);

-- Trigger for updated_at
CREATE OR REPLACE FUNCTION update_timestamp()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_users_timestamp
BEFORE UPDATE ON users
FOR EACH ROW
EXECUTE FUNCTION update_timestamp();

-- Comments
COMMENT ON TABLE users IS 'Users of the system including doctors, nurses, and administrative staff';
COMMENT ON COLUMN users.id IS 'Unique identifier for the user';
COMMENT ON COLUMN users.username IS 'Username for login';
-- Additional column comments...
```

Similar schema definitions were created for other core entities:

- **Patients**: Storing patient demographic and medical information
- **Appointments**: Managing scheduled meetings between doctors and patients
- **Encounters**: Representing actual clinical visits or interactions
- **Prescriptions**: Tracking medications prescribed to patients
- **Orders**: Managing clinical orders such as lab tests or imaging
- **Tasks**: Tracking work items for users to complete
- **Alerts**: Notifying users of important events

#### 2. MongoDB Schema Definitions

For flexible schema data like clinical notes and voice recordings, we created MongoDB schema definitions using Mongoose:

```javascript
/**
 * Clinical Notes Schema
 * Represents the documentation of a clinical encounter
 */

const mongoose = require('mongoose');
const Schema = mongoose.Schema;

// Subjective section schema
const SubjectiveSchema = new Schema({
  chiefComplaint: String,
  historyOfPresentIllness: String,
  reviewOfSystems: {
    constitutional: String,
    cardiovascular: String,
    respiratory: String,
    // Other systems...
  },
  pastMedicalHistory: String,
  medications: String,
  allergies: String,
  familyHistory: String,
  socialHistory: String
});

// Other section schemas (Objective, Assessment, Plan)...

// Main clinical note schema
const ClinicalNoteSchema = new Schema({
  encounterId: {
    type: String,
    required: true,
    index: true
  },
  patientId: {
    type: String,
    required: true,
    index: true
  },
  doctorId: {
    type: String,
    required: true,
    index: true
  },
  status: {
    type: String,
    enum: ['draft', 'signed', 'amended'],
    default: 'draft',
    index: true
  },
  noteType: {
    type: String,
    enum: ['soap', 'progress', 'procedure', 'discharge', 'referral', 'consultation'],
    default: 'soap',
    index: true
  },
  content: ContentSchema,
  rawTranscription: String,
  aiSummary: String,
  aiConfidenceScore: Number,
  signedBy: String,
  signedAt: Date,
  metadata: MetadataSchema,
  tags: [String],
  attachments: [Schema.Types.ObjectId],
  createdAt: {
    type: Date,
    default: Date.now,
    index: true
  },
  updatedAt: {
    type: Date,
    default: Date.now,
    index: true
  }
});

// Add index for full-text search
ClinicalNoteSchema.index({
  'content.subjective.chiefComplaint': 'text',
  'content.subjective.historyOfPresentIllness': 'text',
  'content.assessment.clinicalImpression': 'text',
  'content.plan.followUp': 'text',
  rawTranscription: 'text'
});

// Update the updatedAt field on save
ClinicalNoteSchema.pre('save', function(next) {
  this.updatedAt = Date.now();
  next();
});

module.exports = ClinicalNoteSchema;
```

#### 3. Migration Scripts

We created migration scripts to set up the database schema in a consistent and repeatable way:

```sql
-- V1__initial_schema.sql
-- Initial database schema for Dr. Assistant

-- Enable UUID extension
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create update_timestamp function for triggers
CREATE OR REPLACE FUNCTION update_timestamp()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Users Table
CREATE TABLE IF NOT EXISTS users (
    -- User table definition...
);

-- Patients Table
CREATE TABLE IF NOT EXISTS patients (
    -- Patient table definition...
);

-- Appointments Table
CREATE TABLE IF NOT EXISTS appointments (
    -- Appointment table definition...
);

-- Encounters Table
CREATE TABLE IF NOT EXISTS encounters (
    -- Encounter table definition...
);
```

For MongoDB, we created an initialization script:

```javascript
/**
 * MongoDB Initial Setup Script
 * This script initializes the MongoDB collections and indexes
 */

// Create collections
db.createCollection('clinicalNotes');
db.createCollection('voiceRecordings');
db.createCollection('fs.files');
db.createCollection('fs.chunks');

// Create indexes for clinicalNotes collection
db.clinicalNotes.createIndex({ encounterId: 1 });
db.clinicalNotes.createIndex({ patientId: 1 });
db.clinicalNotes.createIndex({ doctorId: 1 });
// Additional indexes...

// Create indexes for voiceRecordings collection
db.voiceRecordings.createIndex({ encounterId: 1 });
db.voiceRecordings.createIndex({ patientId: 1 });
// Additional indexes...

// Create indexes for GridFS collections
db.fs.files.createIndex({ filename: 1 });
db.fs.files.createIndex({ uploadDate: 1 });
db.fs.chunks.createIndex({ files_id: 1, n: 1 }, { unique: true });
```

#### 4. Entity Relationship Diagram

We created a detailed Entity Relationship Diagram (ERD) to visualize the relationships between entities:

```
┌───────────────┐       ┌───────────────┐       ┌───────────────┐
│               │       │               │       │               │
│     User      │◄──────┤  Appointment  │───────►    Patient    │
│               │1     *│               │*     1│               │
└───────┬───────┘       └───────┬───────┘       └───────┬───────┘
        │                       │                       │
        │                       │                       │
        │                       │                       │
        │                       ▼                       │
        │               ┌───────────────┐               │
        │               │               │               │
        └──────────────►│   Encounter   │◄──────────────┘
                      *│               │*
                       └───────┬───────┘
                               │
                               │
          ┌────────────────────┼────────────────────┐
          │                    │                    │
          ▼                    ▼                    ▼
┌───────────────┐     ┌───────────────┐     ┌───────────────┐
│               │     │               │     │               │
│ Clinical Note │     │  Prescription │     │    Order      │
│               │     │               │     │               │
└───────────────┘     └───────┬───────┘     └───────┬───────┘
                              │                     │
                              ▼                     ▼
                     ┌───────────────┐     ┌───────────────┐
                     │               │     │               │
                     │ Prescription  │     │  Order Item   │
                     │     Item      │     │               │
                     │               │     │               │
                     └───────────────┘     └───────────────┘
```

The ERD document included detailed explanations of entity relationships, cardinality notation, and database technologies used.

#### 5. Data Access Patterns

We documented common data access patterns to guide the implementation of data access layers:

```markdown
## Common Query Patterns

### 1. Doctor's Daily Dashboard

The doctor's daily dashboard requires efficient retrieval of appointments, tasks, and alerts for the current day.

#### Appointments for Today

```sql
-- Get today's appointments for a doctor
SELECT a.*, p.first_name, p.last_name, p.date_of_birth
FROM appointments a
JOIN patients p ON a.patient_id = p.id
WHERE a.doctor_id = :doctorId
AND DATE(a.start_time) = CURRENT_DATE
ORDER BY a.start_time;
```

#### Pending Tasks

```sql
-- Get pending tasks for a doctor
SELECT t.*, p.first_name, p.last_name
FROM tasks t
LEFT JOIN patients p ON t.patient_id = p.id
WHERE t.assigned_to = :doctorId
AND t.status = 'pending'
ORDER BY t.priority DESC, t.due_date;
```

### 2. Patient Timeline

The patient timeline requires retrieval of all clinical data for a specific patient.

#### Patient Encounters

```sql
-- Get all encounters for a patient
SELECT e.*, u.full_name as doctor_name
FROM encounters e
JOIN users u ON e.doctor_id = u.id
WHERE e.patient_id = :patientId
ORDER BY e.start_time DESC;
```
```

The document also included caching strategies using Redis and performance considerations.

## Challenges and Solutions

### Challenge 1: Balancing Normalization and Performance

**Challenge:** We needed to design a schema that was properly normalized to avoid data redundancy while still performing well for common query patterns.

**Solution:** We adopted a pragmatic approach to normalization:

1. **Proper Normalization**: We normalized the schema to avoid data redundancy and maintain data integrity.

2. **Strategic Denormalization**: For performance-critical paths, we selectively denormalized data. For example, we included patient name in the appointments table to avoid joins for simple appointment listings.

3. **Caching Strategy**: We designed a caching strategy using Redis to cache frequently accessed data, reducing database load.

```javascript
// Example of caching strategy for doctor's daily schedule
async function getDoctorDailySchedule(doctorId, date) {
  const cacheKey = `doctor:${doctorId}:schedule:${date}`;
  
  // Try to get from cache first
  const cachedSchedule = await redisClient.get(cacheKey);
  if (cachedSchedule) {
    return JSON.parse(cachedSchedule);
  }
  
  // If not in cache, query database
  const schedule = await appointmentRepository.findByDoctorAndDate(doctorId, date);
  
  // Cache the result with expiration
  await redisClient.set(cacheKey, JSON.stringify(schedule), 'EX', 3600); // 1 hour expiration
  
  return schedule;
}
```

### Challenge 2: Handling Flexible Schema Data

**Challenge:** Some data, like clinical notes, had a flexible structure that didn't fit well in a relational database.

**Solution:** We implemented a polyglot persistence approach:

1. **PostgreSQL for Structured Data**: We used PostgreSQL for structured data with well-defined relationships.

2. **MongoDB for Flexible Schema Data**: We used MongoDB for data with flexible schemas, like clinical notes and voice recordings.

3. **Cross-Database Relationships**: We maintained relationships between PostgreSQL and MongoDB using string UUIDs.

```javascript
// Example of cross-database relationship
// In PostgreSQL encounters table
CREATE TABLE encounters (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    // Other fields...
);

// In MongoDB clinical notes schema
const ClinicalNoteSchema = new Schema({
  encounterId: {
    type: String, // UUID from PostgreSQL stored as string
    required: true,
    index: true
  },
  // Other fields...
});
```

### Challenge 3: Planning for Scale

**Challenge:** We needed to design a schema that would scale as the application grew, without requiring major restructuring.

**Solution:** We implemented several strategies for scalability:

1. **Appropriate Indexing**: We created indexes for all columns used in WHERE clauses, JOIN conditions, and ORDER BY statements.

2. **Partitioning Strategy**: We designed the schema with future partitioning in mind, particularly for time-series data like appointments and encounters.

3. **Sharding Considerations**: For MongoDB collections, we considered future sharding requirements in our schema design.

```sql
-- Example of index creation for scalability
CREATE INDEX idx_appointments_doctor_date ON appointments(doctor_id, DATE(start_time));
CREATE INDEX idx_encounters_patient_time ON encounters(patient_id, start_time DESC);
```

## Impact and Outcomes

The implementation of MVP-004 had several significant impacts:

1. **Solid Data Foundation**: The well-designed data model provided a solid foundation for all application features.

2. **Performance Optimization**: The careful consideration of indexes and access patterns resulted in good performance from the start.

3. **Data Integrity**: The use of constraints, foreign keys, and triggers ensured data integrity across the application.

4. **Development Clarity**: The clear entity relationships and access patterns made it easier for developers to understand how to interact with the data.

5. **Future-Proofing**: The scalable design meant that the data model could grow with the application without major restructuring.

## Lessons Learned

1. **Document Everything**: Comprehensive documentation of the data model, including ERDs, access patterns, and schema details, proved invaluable for the development team.

2. **Think About Access Patterns Early**: Considering how data would be accessed from the beginning helped us design a schema that performed well for real-world usage.

3. **Balance Theory and Practicality**: While database normalization theory is important, practical considerations like performance and developer experience are equally crucial.

4. **Plan for Evolution**: Even the best-designed schema will need to evolve. Building in flexibility and clear migration paths from the start made future changes easier.

5. **Test with Realistic Data Volumes**: Testing the schema with realistic data volumes early on helped identify potential performance issues before they became problems in production.

## Connection to Other Tickets

MVP-004 was directly connected to several other tickets:

- **MVP-001 (Project Initialization and Documentation Setup)**: The data model built upon the conceptual model defined in the initial documentation.

- **MVP-007 (Implement Database Infrastructure)**: The schema definitions and migration scripts created in MVP-004 would be used to set up the actual database infrastructure.

- **MVP-006 (Implement Authentication & Authorization)**: The user schema defined in MVP-004 would be used for authentication and authorization.

- **MVP-008 (Implement User Management)**: The user schema and relationships would be the foundation for user management features.

## Conclusion

MVP-004 established the data foundation for the Dr. Assistant application. By carefully designing the database schema, entity relationships, and access patterns, we created a solid base that would support all the features we planned to build.

The polyglot persistence approach, combining PostgreSQL for structured data and MongoDB for flexible schema data, gave us the best of both worlds: the reliability and consistency of a relational database where appropriate, and the flexibility of a document database where needed.

As we move forward with implementing specific features, the data model defined in MVP-004 will continue to guide our development, ensuring data integrity, performance, and scalability throughout the application lifecycle.
